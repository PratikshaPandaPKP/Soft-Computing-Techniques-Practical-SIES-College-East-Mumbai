{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQQu8La8U10T",
        "outputId": "098dc3b1-39ba-46d3-d71e-555a16fd2b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights: [0. 0.]\n",
            "After input [1 1], target 1: weights = [0.01 0.01]\n",
            "After input [ 1 -1], target -1: weights = [0.   0.02]\n",
            "After input [-1  1], target -1: weights = [0.01 0.01]\n",
            "After input [-1 -1], target -1: weights = [0.02 0.02]\n",
            "Final weights after training: [0.02 0.02]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the inputs and target output (training data)\n",
        "# Each row represents an input vector [x1, x2]\n",
        "# The corresponding target output is stored in `target_output`\n",
        "input_data = np.array([\n",
        "    [1, 1],\n",
        "    [1, -1],\n",
        "    [-1, 1],\n",
        "    [-1, -1]\n",
        "])\n",
        "\n",
        "# Define the target output for each input pair\n",
        "# For example, in an AND gate, it would be [1, -1, -1, -1]\n",
        "target_output = np.array([1, -1, -1, -1])\n",
        "\n",
        "# Initialize weights and learning rate\n",
        "weights = np.array([0.0, 0.0])  # Start with zero weights\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Hebb's learning rule function\n",
        "def hebbian_learning(input_data, target_output, weights):\n",
        "    for i in range(len(input_data)):\n",
        "        # Calculate the weight update: Î”w = x * y\n",
        "        delta_w = learning_rate * input_data[i] * target_output[i]\n",
        "        # Update weights\n",
        "        weights += delta_w\n",
        "        # Print the updated weights after each step\n",
        "        print(f\"After input {input_data[i]}, target {target_output[i]}: weights = {weights}\")\n",
        "    return weights\n",
        "\n",
        "# Train the neuron using Hebb's rule\n",
        "print(\"Initial weights:\", weights)\n",
        "weights = hebbian_learning(input_data, target_output, weights)\n",
        "\n",
        "print(\"Final weights after training:\", weights)\n"
      ]
    }
  ]
}